{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Neural Network\n",
    "\n",
    "In the previous notebook we said that training a neural network happens in two steps:\n",
    "\n",
    "**Forward Propagation**: In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess.\n",
    "\n",
    "**Backward Propagation**: In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collecting the *derivatives* of the error with respect to the parameters of the functions (gradients), and uses this gradient to adjust its internal values.\n",
    "\n",
    "In the previous notebook where we implemented the `Value` object, which is used to perform the backward propagation. In this notebook, we'll implement the forward pass for a single neuron and then for a full neural network. We'll then combine this with the backward propagation to train on a real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To allow importing modules from the nnfs directory, can be ignored\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the 'src' directory\n",
    "src_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "# Add 'src' directory to the Python path\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Must first download graphviz: https://graphviz.org/download/\n",
    "\n",
    "from nnfs.helpers import draw_dot, np_array_to_list_of_values\n",
    "from nnfs.autograd import Value\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neuron\n",
    "\n",
    "An artificial neuron is a fundamental building block of dense neural networks. It's inspired by biological neurons in the human brain, but is a simplified, mathematical model.\n",
    "\n",
    "![An artificial neuron](img/neuron_model.png)\n",
    "\n",
    "Here's a basic breakdown:\n",
    "\n",
    "1. **Inputs**: The artificial neuron receives one or more inputs $x_i$. These could be raw data points, like pixels from an image, or outputs from other neurons.\n",
    "2. **Weights**: Each input $x_i$ has an associated weight $w_i$, which can be adjusted over using backprop. Think of these weights as dials or knobs that can be turned to make the neuron behave differently. Each neuron also has a bias $b$, which is a baseline constant that can also be adjusted.\n",
    "4. **Summation**: The neuron multiplies each input $x_i$ by its weight $w_i$, then sums up all these products, and adds the bias $b$. ($\\sum_{i=1}^{n} w_i x_i + b$)\n",
    "4. **Activation Function**: This sum then passes through an activation function $f$. The purpose of this function is to introduce non-linearity to the model, which allows neural networks to learn complex patterns. Common activation functions include the sigmoid, ReLU, and tanh.\n",
    "5. **Output**: The result from the activation function is the output of the neuron, which can then serve as an input to another neuron in the next layer of a neural network.\n",
    "\n",
    "In essence, the artificial neuron takes in data, processes it using its weights and the activation function, and then outputs a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Function\n",
    "\n",
    "In this notebook, we'll use the $\\tanh$ as activation function, which is defined as:\n",
    "\n",
    "$$\\tanh(x) = \\frac{e^{2x} - 1}{e^{2x} + 1}$$\n",
    "\n",
    "$\\tanh$, is a mathematical function that squishes the input values to and s-curve with values in the range (-1, 1).\n",
    "It is useful as an activation function because it smooth, differential, and non-linear with values centered around zero, which are \n",
    "all properties that are useful for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(-5,5,0.2), np.tanh(np.arange(-5,5,0.2)))\n",
    "plt.grid()\n",
    "plt.title('$tanh(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now implement a neuron with two inputs using the `Value` object. We'll later convert this to a class so we can generalize it to neurons with any number of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.5 (20230430.1635)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1470pt\" height=\"210pt\"\n",
       " viewBox=\"0.00 0.00 1470.25 210.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 206)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-206 1466.25,-206 1466.25,4 -4,4\"/>\n",
       "<!-- 2233358543376 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2233358543376</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"618.5,-137.5 618.5,-173.5 804.5,-173.5 804.5,-137.5 618.5,-137.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.25\" y=\"-150.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"642,-137.75 642,-173.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"682.25\" y=\"-150.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 6.8813</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"722.5,-137.75 722.5,-173.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"763.5\" y=\"-150.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2232818361120+ -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>2232818361120+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"867.5\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"867.5\" y=\"-122.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 2233358543376&#45;&gt;2232818361120+ -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2233358543376&#45;&gt;2232818361120+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M804.31,-138.81C813.41,-137.15 822.23,-135.55 830.23,-134.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"830.72,-137.38 839.93,-132.15 829.46,-130.49 830.72,-137.38\"/>\n",
       "</g>\n",
       "<!-- 2232819552304 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2232819552304</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2.25,-165.5 2.25,-201.5 197.25,-201.5 197.25,-165.5 2.25,-165.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"18.5\" y=\"-178.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"34.75,-165.75 34.75,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"75\" y=\"-178.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 1.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"115.25,-165.75 115.25,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"156.25\" y=\"-178.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2233360185952* -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2233360185952*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"262.5\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"262.5\" y=\"-123.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 2232819552304&#45;&gt;2233360185952* -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2232819552304&#45;&gt;2233360185952*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.84,-165.51C181.21,-162.72 190.64,-159.69 199.5,-156.5 209.81,-152.79 220.79,-148.09 230.6,-143.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"231.74,-146.47 239.32,-139.06 228.78,-140.13 231.74,-146.47\"/>\n",
       "</g>\n",
       "<!-- 2233360185952 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2233360185952</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"327.75,-110.5 327.75,-146.5 490.25,-146.5 490.25,-110.5 327.75,-110.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"368\" y=\"-123.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"408.25,-110.75 408.25,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"449.25\" y=\"-123.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2232818362848+ -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>2232818362848+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"555.5\" cy=\"-100.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"555.5\" y=\"-95.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 2233360185952&#45;&gt;2232818362848+ -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>2233360185952&#45;&gt;2232818362848+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M489.86,-113.03C499.86,-111.09 509.67,-109.19 518.5,-107.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"518.96,-110.76 528.11,-105.42 517.63,-103.89 518.96,-110.76\"/>\n",
       "</g>\n",
       "<!-- 2233360185952*&#45;&gt;2233360185952 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2233360185952*&#45;&gt;2233360185952</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.67,-128.5C297.73,-128.5 307.11,-128.5 316.99,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"316.87,-132 326.87,-128.5 316.87,-125 316.87,-132\"/>\n",
       "</g>\n",
       "<!-- 2232818361072 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2232818361072</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1260.5,-109.5 1260.5,-145.5 1462.25,-145.5 1462.25,-109.5 1260.5,-109.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1280.12\" y=\"-122.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yhat</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1299.75,-109.75 1299.75,-145.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1340\" y=\"-122.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.7071</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1380.25,-109.75 1380.25,-145.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1421.25\" y=\"-122.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2232818361072tanh -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2232818361072tanh</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1197.5\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1197.5\" y=\"-122.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 2232818361072tanh&#45;&gt;2232818361072 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2232818361072tanh&#45;&gt;2232818361072</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1224.87,-127.5C1232.21,-127.5 1240.67,-127.5 1249.71,-127.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1249.54,-131 1259.54,-127.5 1249.54,-124 1249.54,-131\"/>\n",
       "</g>\n",
       "<!-- 2232818361120 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2232818361120</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"930.5,-109.5 930.5,-145.5 1134.5,-145.5 1134.5,-109.5 930.5,-109.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"951.25\" y=\"-122.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Sum</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"972,-109.75 972,-145.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1012.25\" y=\"-122.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.8813</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1052.5,-109.75 1052.5,-145.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1093.5\" y=\"-122.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2232818361120&#45;&gt;2232818361072tanh -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>2232818361120&#45;&gt;2232818361072tanh</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1134.41,-127.5C1143.25,-127.5 1151.77,-127.5 1159.51,-127.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1159.25,-131 1169.25,-127.5 1159.25,-124 1159.25,-131\"/>\n",
       "</g>\n",
       "<!-- 2232818361120+&#45;&gt;2232818361120 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2232818361120+&#45;&gt;2232818361120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M894.69,-127.5C902.06,-127.5 910.58,-127.5 919.69,-127.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"919.61,-131 929.61,-127.5 919.61,-124 919.61,-131\"/>\n",
       "</g>\n",
       "<!-- 2233358541600 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>2233358541600</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-55.5 0,-91.5 199.5,-91.5 199.5,-55.5 0,-55.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"16.25\" y=\"-68.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"32.5,-55.75 32.5,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"75\" y=\"-68.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;3.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"117.5,-55.75 117.5,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"158.5\" y=\"-68.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2233360185760* -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>2233360185760*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"262.5\" cy=\"-73.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"262.5\" y=\"-68.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 2233358541600&#45;&gt;2233360185760* -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>2233358541600&#45;&gt;2233360185760*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M199.35,-73.5C208.17,-73.5 216.68,-73.5 224.43,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.18,-77 234.18,-73.5 224.18,-70 224.18,-77\"/>\n",
       "</g>\n",
       "<!-- 2233358541648 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>2233358541648</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3.75,-110.5 3.75,-146.5 195.75,-146.5 195.75,-110.5 3.75,-110.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"18.5\" y=\"-123.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"33.25,-110.75 33.25,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.5\" y=\"-123.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"113.75,-110.75 113.75,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"154.75\" y=\"-123.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2233358541648&#45;&gt;2233360185952* -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>2233358541648&#45;&gt;2233360185952*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195.65,-128.5C205.67,-128.5 215.38,-128.5 224.13,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.01,-132 234.01,-128.5 224.01,-125 224.01,-132\"/>\n",
       "</g>\n",
       "<!-- 2233358541696 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>2233358541696</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3.75,-0.5 3.75,-36.5 195.75,-36.5 195.75,-0.5 3.75,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"18.5\" y=\"-13.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"33.25,-0.75 33.25,-36.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.5\" y=\"-13.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 2.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"113.75,-0.75 113.75,-36.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"154.75\" y=\"-13.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2233358541696&#45;&gt;2233360185760* -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2233358541696&#45;&gt;2233360185760*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168.6,-36.43C179.02,-39.56 189.6,-42.96 199.5,-46.5 209.57,-50.1 220.32,-54.56 229.99,-58.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"228.42,-62.38 238.98,-63.28 231.29,-56 228.42,-62.38\"/>\n",
       "</g>\n",
       "<!-- 2233360185760 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>2233360185760</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"325.5,-55.5 325.5,-91.5 492.5,-91.5 492.5,-55.5 325.5,-55.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"368\" y=\"-68.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"410.5,-55.75 410.5,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"451.5\" y=\"-68.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2233360185760&#45;&gt;2232818362848+ -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2233360185760&#45;&gt;2232818362848+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M492.38,-88.89C501.43,-90.58 510.26,-92.23 518.29,-93.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"517.58,-97.35 528.05,-95.74 518.86,-90.47 517.58,-97.35\"/>\n",
       "</g>\n",
       "<!-- 2233360185760*&#45;&gt;2233360185760 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2233360185760*&#45;&gt;2233360185760</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.67,-73.5C297.15,-73.5 305.76,-73.5 314.86,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"314.72,-77 324.72,-73.5 314.72,-70 314.72,-77\"/>\n",
       "</g>\n",
       "<!-- 2232818362848 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>2232818362848</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"628,-82.5 628,-118.5 795,-118.5 795,-82.5 628,-82.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"670.5\" y=\"-95.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"713,-82.75 713,-118.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"754\" y=\"-95.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2232818362848&#45;&gt;2232818361120+ -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>2232818362848&#45;&gt;2232818361120+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M794.91,-114.95C807.33,-117.13 819.56,-119.27 830.3,-121.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"829.45,-124.73 839.9,-123.01 830.66,-117.84 829.45,-124.73\"/>\n",
       "</g>\n",
       "<!-- 2232818362848+&#45;&gt;2232818362848 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2232818362848+&#45;&gt;2232818362848</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M582.97,-100.5C592.92,-100.5 604.87,-100.5 617.43,-100.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"617.08,-104 627.08,-100.5 617.08,-97 617.08,-104\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x207fe9b57b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [Value(2.0, label='x1'), Value(0.0, label='x2')]  # inputs\n",
    "w = [Value(-3.0, label='w1'), Value(1.0, label='w2')]  # weights\n",
    "b = Value(6.8813, label='b')  # bias\n",
    "\n",
    "# forward pass\n",
    "f = x[0] * w[0] + x[1] * w[1] + b; f.label = 'Sum'  # Summation\n",
    "yhat = f.tanh(); yhat.label = 'yhat'  # Activation function\n",
    "\n",
    "draw_dot(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all there is to a forward pass of a single neuron: multiply inputs with weights, sum them up, add the bias, and pass them through an activation function. We can now easily generalize this to a neuron with any number of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "  \n",
    "    def __init__(self, num_inputs, activation='tanh'):\n",
    "        \"\"\"Initialize the weights and bias randomly, and set the activation function\"\"\"\n",
    "        self.w = [Value(random.uniform(-1,1), label=f'w_{i+1}') for i in range(num_inputs)]\n",
    "        self.b = Value(random.uniform(-1,1), label='b')\n",
    "        self.activation = activation\n",
    "  \n",
    "    def __call__(self, x):\n",
    "        \"\"\"The forward pass of a single neuron\"\"\"\n",
    "        # Check that the number of inputs equals the number of weights\n",
    "        if len(x) != len(self.w):\n",
    "            raise ValueError(f'Expected {len(self.w)} inputs, got {len(x)}')\n",
    "        \n",
    "        act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)  # sum(w * x) + b\n",
    "        if self.activation == 'tanh':\n",
    "            out = act.tanh()\n",
    "        elif self.activation == 'relu': # The ReLU activation equals to max(0, x)\n",
    "            out = act.relu()\n",
    "        else:  # The output of the neuron stays linear\n",
    "            out = act\n",
    "        return out\n",
    "  \n",
    "    def parameters(self):  \n",
    "        \"\"\"Return the weights and bias as a list\"\"\"\n",
    "        return self.w + [self.b]\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Reset the gradients to zero\"\"\"\n",
    "        for p in self.parameters():\n",
    "            p.grad = 0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.activation == 'tanh':\n",
    "            neuron_type = 'Tanh'\n",
    "        elif self.activation == 'relu':\n",
    "            neuron_type = 'ReLU'\n",
    "        else:\n",
    "            neuron_type = 'Linear'\n",
    "        return f'{neuron_type}Neuron({len(self.w)})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We usually initialize the weights randomly. If all weights are initialized with the same value, every neuron in the hidden layer will produce the same output and undergo the same weight updates during training. This makes the neurons in that layer symmetric and redundant. Random initialization ensures that each neuron starts with a different weight and thus follows a unique gradient during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `Neuron` to do linear regression\n",
    "\n",
    "A single `Neuron` is able to do standard linear regression if we do not use an activation function. We'll generate a simple dataset $y=2 x_1+ 0.8x_2 + \\epsilon$, where $x_i$ are the inputs, $\\epsilon$ is a random noise term, and $y$ is the target. We'll use this dataset to demonstrate how to train a single neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.random((50, 2))\n",
    "eps = np.random.random((50, )) * 0.2\n",
    "y = 2 * x[:, 0] + 0.8 * x[:, 1] + eps\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(11, 5))\n",
    "\n",
    "axs[0].scatter(x[:,0], y, label='x1')\n",
    "axs[0].set_xlabel('$x_1$')\n",
    "axs[0].set_ylabel('$y$')\n",
    "\n",
    "axs[1].scatter(x[:,1], y, label='x2')\n",
    "axs[1].set_xlabel('$x_2$')\n",
    "axs[1].set_ylabel('$y$')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.suptitle('$x_i$ vs $y$ for our generated dataset', y=1.03, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly train our model we need a score to measure how well the model is doing. The goal of the model is to minimize this score during training. The score is called the loss (or cost) function in ML literature. In our linear regression example, we'll minimize the mean squared error (MSE), which is the default loss function for regression problems. The MSE is defined as\n",
    "the average of the squared difference between the predicted and actual values. Or in mathematical notation:\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "where $n$ is the number of samples, $y_i$ is the actual value, and $\\hat{y}_i$ is the predicted value.\n",
    "\n",
    "We'll start with minimizing the MSE for one iteration and for one sample to see to that everything works as expected. We'll then extend it to all samples in the dataset over multiple iterations to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearNeuron(2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    # Convert inputs to lists of values if they are scalars\n",
    "    if not hasattr(y_true, '__iter__'):\n",
    "        y_true = [y_true]\n",
    "    if not hasattr(y_pred, '__iter__'):\n",
    "        y_pred = [y_pred]\n",
    "        \n",
    "    num_items = len(y_true)\n",
    "    return sum((y_i - pred_i)**2 for y_i, pred_i in zip(y_true, y_pred)) / num_items\n",
    "\n",
    "\n",
    "linear_model = Neuron(num_inputs=2, activation='linear')  # num_inputs = number of features\n",
    "linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(7.6430, grad=0.0000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass\n",
    "output = linear_model(x[0])\n",
    "loss = mse(y[0], output)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to do the backwards pass. Since we're using the `Value` object we implemented in the last notebook, it will be very simple. Just call `.backward()` on the loss value and it will compute the derivative of the loss with respect to the weights.\n",
    "\n",
    "The derivatives show how the loss will respond if we change the weights a tiny nudge. We can use this fact to adjust the weights in the direction that reduces the loss. We can demonstrate this with a simple image:\n",
    "\n",
    "![Gradient Descent](img/gradient_descent.png)\n",
    "\n",
    "In the image above, the current position is the loss of the model with the current weights. The derivative of the loss function with repsect to the weight gives slope of the loss function at the current position. We can use the slope to nudge the weights in the direction downwards so that the loss is reduced. Doing this iteratively will move the weights close to the bottom of the loss function, which is the point where the loss is minimized.\n",
    "\n",
    "It should be noted that not all problems and loss functions have this smooth bowl shape. Most problems are much more complex and have many hills and valleys. This means that we can't just take a huge single step in the direction of the slope to get to the bottom. We need to take many smaller steps and each time find the new slope to reach the bottom of the valley. We can't know the slope of a point we haven't reached yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.5 (20230430.1635)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"2629pt\" height=\"263pt\"\n",
       " viewBox=\"0.00 0.00 2628.50 263.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 259)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-259 2624.5,-259 2624.5,4 -4,4\"/>\n",
       "<!-- 2233360772656 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2233360772656</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"670.5,-55.5 670.5,-91.5 842,-91.5 842,-55.5 670.5,-55.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"713\" y=\"-68.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;0.9032</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"755.5,-55.75 755.5,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"798.75\" y=\"-68.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;5.5292</text>\n",
       "</g>\n",
       "<!-- 2233360766800+ -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>2233360766800+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"905\" cy=\"-100.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"905\" y=\"-95.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 2233360772656&#45;&gt;2233360766800+ -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>2233360772656&#45;&gt;2233360766800+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M841.76,-89.05C850.86,-90.72 859.72,-92.35 867.77,-93.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"867.08,-97.45 877.55,-95.82 868.35,-90.57 867.08,-97.45\"/>\n",
       "</g>\n",
       "<!-- 2233360772656* -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2233360772656*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"607.5\" cy=\"-73.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"607.5\" y=\"-68.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 2233360772656*&#45;&gt;2233360772656 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2233360772656*&#45;&gt;2233360772656</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M634.74,-73.5C642.2,-73.5 650.8,-73.5 659.89,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"659.75,-77 669.75,-73.5 659.75,-70 659.75,-77\"/>\n",
       "</g>\n",
       "<!-- 2233360767040 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2233360767040</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1842.5,-191.5 1842.5,-227.5 2005,-227.5 2005,-191.5 1842.5,-191.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1882.75\" y=\"-204.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1923,-191.75 1923,-227.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1964\" y=\"-204.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 2233360767136+ -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>2233360767136+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2068\" cy=\"-181.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2068\" y=\"-176.07\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 2233360767040&#45;&gt;2233360767136+ -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>2233360767040&#45;&gt;2233360767136+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2004.61,-193.78C2013.84,-191.96 2022.87,-190.19 2031.07,-188.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2031.53,-191.85 2040.67,-186.49 2030.18,-184.98 2031.53,-191.85\"/>\n",
       "</g>\n",
       "<!-- 2233360772704 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2233360772704</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"357.5,-55.5 357.5,-91.5 520,-91.5 520,-55.5 357.5,-55.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"397.75\" y=\"-68.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.9507</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"438,-55.75 438,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"479\" y=\"-68.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 5.2526</text>\n",
       "</g>\n",
       "<!-- 2233360772704&#45;&gt;2233360772656* -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>2233360772704&#45;&gt;2233360772656*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M519.71,-73.5C537.16,-73.5 554.81,-73.5 569.59,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"569.29,-77 579.29,-73.5 569.29,-70 569.29,-77\"/>\n",
       "</g>\n",
       "<!-- 2233360773232 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2233360773232</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"670.5,-110.5 670.5,-146.5 842,-146.5 842,-110.5 670.5,-110.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"713\" y=\"-123.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;0.3455</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"755.5,-110.75 755.5,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"798.75\" y=\"-123.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;5.5292</text>\n",
       "</g>\n",
       "<!-- 2233360773232&#45;&gt;2233360766800+ -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>2233360773232&#45;&gt;2233360766800+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M841.76,-112.37C850.86,-110.64 859.72,-108.95 867.77,-107.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"868.38,-110.67 877.55,-105.36 867.07,-103.79 868.38,-110.67\"/>\n",
       "</g>\n",
       "<!-- 2233360773232+ -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2233360773232+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"607.5\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"607.5\" y=\"-123.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 2233360773232+&#45;&gt;2233360773232 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2233360773232+&#45;&gt;2233360773232</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M634.74,-128.5C642.2,-128.5 650.8,-128.5 659.89,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"659.75,-132 669.75,-128.5 659.75,-125 659.75,-132\"/>\n",
       "</g>\n",
       "<!-- 2233360767136 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2233360767136</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2131,-163.5 2131,-199.5 2293.5,-199.5 2293.5,-163.5 2131,-163.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2171.25\" y=\"-176.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 7.6430</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"2211.5,-163.75 2211.5,-199.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2252.5\" y=\"-176.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 2233360772800* -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>2233360772800*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2356.5\" cy=\"-208.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2356.5\" y=\"-203.07\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 2233360767136&#45;&gt;2233360772800* -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>2233360767136&#45;&gt;2233360772800*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2293.11,-196.66C2302.34,-198.41 2311.37,-200.12 2319.57,-201.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2318.69,-205.27 2329.17,-203.69 2320,-198.39 2318.69,-205.27\"/>\n",
       "</g>\n",
       "<!-- 2233360767136+&#45;&gt;2233360767136 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2233360767136+&#45;&gt;2233360767136</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2095.42,-181.5C2102.87,-181.5 2111.42,-181.5 2120.43,-181.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2120.18,-185 2130.18,-181.5 2120.18,-178 2120.18,-185\"/>\n",
       "</g>\n",
       "<!-- 2233360772800 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>2233360772800</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2419.5,-190.5 2419.5,-226.5 2620.5,-226.5 2620.5,-190.5 2419.5,-190.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2438.75\" y=\"-203.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">loss</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"2458,-190.75 2458,-226.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2498.25\" y=\"-203.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 7.6430</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"2538.5,-190.75 2538.5,-226.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2579.5\" y=\"-203.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 2233360772800*&#45;&gt;2233360772800 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2233360772800*&#45;&gt;2233360772800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2383.81,-208.5C2391.2,-208.5 2399.72,-208.5 2408.83,-208.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2408.74,-212 2418.74,-208.5 2408.74,-205 2408.74,-212\"/>\n",
       "</g>\n",
       "<!-- 2233360771456 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>2233360771456</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"20,-138.5 20,-174.5 187,-174.5 187,-138.5 20,-138.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.25\" y=\"-151.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.3745</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"100.5,-138.75 100.5,-174.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"143.75\" y=\"-151.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;1.5418</text>\n",
       "</g>\n",
       "<!-- 2233360765744* -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>2233360765744*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"270\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"270\" y=\"-123.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 2233360771456&#45;&gt;2233360765744* -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>2233360771456&#45;&gt;2233360765744*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M186.75,-142.5C202.81,-139.77 218.88,-137.03 232.49,-134.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"233.03,-138 242.3,-132.88 231.85,-131.1 233.03,-138\"/>\n",
       "</g>\n",
       "<!-- 2233360772848 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>2233360772848</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"341.25,-165.5 341.25,-201.5 536.25,-201.5 536.25,-165.5 341.25,-165.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-178.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"364.75,-165.75 364.75,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"407.25\" y=\"-178.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;0.4499</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"449.75,-165.75 449.75,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"493\" y=\"-178.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;5.5292</text>\n",
       "</g>\n",
       "<!-- 2233360772848&#45;&gt;2233360773232+ -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>2233360772848&#45;&gt;2233360773232+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M515.74,-165.56C525.5,-162.78 535.29,-159.74 544.5,-156.5 554.84,-152.86 565.82,-148.19 575.63,-143.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"576.78,-146.56 584.35,-139.14 573.81,-140.22 576.78,-146.56\"/>\n",
       "</g>\n",
       "<!-- 2233360774912 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>2233360774912</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1554,-136.5 1554,-172.5 1716.5,-172.5 1716.5,-136.5 1554,-136.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1594.25\" y=\"-149.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 2.7646</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1634.5,-136.75 1634.5,-172.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1675.5\" y=\"-149.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 5.5292</text>\n",
       "</g>\n",
       "<!-- 2233360773424**2 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>2233360773424**2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1779.5\" cy=\"-154.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1779.5\" y=\"-149.07\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">**2</text>\n",
       "</g>\n",
       "<!-- 2233360774912&#45;&gt;2233360773424**2 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>2233360774912&#45;&gt;2233360773424**2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1716.11,-154.5C1724.87,-154.5 1733.46,-154.5 1741.32,-154.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1741.26,-158 1751.26,-154.5 1741.26,-151 1741.26,-158\"/>\n",
       "</g>\n",
       "<!-- 2233360774912+ -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>2233360774912+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1491\" cy=\"-154.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1491\" y=\"-149.07\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 2233360774912+&#45;&gt;2233360774912 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2233360774912+&#45;&gt;2233360774912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1518.42,-154.5C1525.87,-154.5 1534.42,-154.5 1543.43,-154.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1543.18,-158 1553.18,-154.5 1543.18,-151 1543.18,-158\"/>\n",
       "</g>\n",
       "<!-- 2233360773424 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>2233360773424</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1842.5,-136.5 1842.5,-172.5 2005,-172.5 2005,-136.5 1842.5,-136.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1882.75\" y=\"-149.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 7.6430</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1923,-136.75 1923,-172.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1964\" y=\"-149.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n",
       "</g>\n",
       "<!-- 2233360773424&#45;&gt;2233360767136+ -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>2233360773424&#45;&gt;2233360767136+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2004.61,-169.66C2013.84,-171.41 2022.87,-173.12 2031.07,-174.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2030.19,-178.27 2040.67,-176.69 2031.5,-171.39 2030.19,-178.27\"/>\n",
       "</g>\n",
       "<!-- 2233360773424**2&#45;&gt;2233360773424 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2233360773424**2&#45;&gt;2233360773424</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1806.92,-154.5C1814.37,-154.5 1822.92,-154.5 1831.93,-154.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1831.68,-158 1841.68,-154.5 1831.68,-151 1831.68,-158\"/>\n",
       "</g>\n",
       "<!-- 2233360774960 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>2233360774960</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1265.5,-164.5 1265.5,-200.5 1428,-200.5 1428,-164.5 1265.5,-164.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1305.75\" y=\"-177.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 1.5159</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1346,-164.75 1346,-200.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-177.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 5.5292</text>\n",
       "</g>\n",
       "<!-- 2233360774960&#45;&gt;2233360774912+ -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>2233360774960&#45;&gt;2233360774912+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1427.61,-166.78C1436.84,-164.96 1445.87,-163.19 1454.07,-161.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1454.53,-164.85 1463.67,-159.49 1453.18,-157.98 1454.53,-164.85\"/>\n",
       "</g>\n",
       "<!-- 2233360772944 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>2233360772944</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"968,-137.5 968,-173.5 1139.5,-173.5 1139.5,-137.5 968,-137.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1010.5\" y=\"-150.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;1.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1053,-137.75 1053,-173.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1096.25\" y=\"-150.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;6.9041</text>\n",
       "</g>\n",
       "<!-- 2233360764256* -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>2233360764256*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1202.5\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1202.5\" y=\"-122.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 2233360772944&#45;&gt;2233360764256* -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>2233360772944&#45;&gt;2233360764256*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1139.26,-139.37C1148.36,-137.64 1157.22,-135.95 1165.27,-134.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1165.88,-137.67 1175.05,-132.36 1164.57,-130.79 1165.88,-137.67\"/>\n",
       "</g>\n",
       "<!-- 2233360764256 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>2233360764256</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1265.5,-109.5 1265.5,-145.5 1428,-145.5 1428,-109.5 1265.5,-109.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1305.75\" y=\"-122.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 1.2487</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1346,-109.75 1346,-145.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1387\" y=\"-122.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 5.5292</text>\n",
       "</g>\n",
       "<!-- 2233360764256&#45;&gt;2233360774912+ -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>2233360764256&#45;&gt;2233360774912+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1427.61,-142.66C1436.84,-144.41 1445.87,-146.12 1454.07,-147.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1453.19,-151.27 1463.67,-149.69 1454.5,-144.39 1453.19,-151.27\"/>\n",
       "</g>\n",
       "<!-- 2233360764256*&#45;&gt;2233360764256 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2233360764256*&#45;&gt;2233360764256</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1229.92,-127.5C1237.37,-127.5 1245.92,-127.5 1254.93,-127.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1254.68,-131 1264.68,-127.5 1254.68,-124 1254.68,-131\"/>\n",
       "</g>\n",
       "<!-- 2233360766800 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>2233360766800</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"968,-82.5 968,-118.5 1139.5,-118.5 1139.5,-82.5 968,-82.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1010.5\" y=\"-95.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;1.2487</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1053,-82.75 1053,-118.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1096.25\" y=\"-95.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;5.5292</text>\n",
       "</g>\n",
       "<!-- 2233360766800&#45;&gt;2233360764256* -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>2233360766800&#45;&gt;2233360764256*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1139.26,-116.05C1148.36,-117.72 1157.22,-119.35 1165.27,-120.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1164.58,-124.45 1175.05,-122.82 1165.85,-117.57 1164.58,-124.45\"/>\n",
       "</g>\n",
       "<!-- 2233360766800+&#45;&gt;2233360766800 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2233360766800+&#45;&gt;2233360766800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M932.24,-100.5C939.7,-100.5 948.3,-100.5 957.39,-100.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"957.25,-104 967.25,-100.5 957.25,-97 957.25,-104\"/>\n",
       "</g>\n",
       "<!-- 2233360765744 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>2233360765744</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"355.25,-110.5 355.25,-146.5 522.25,-146.5 522.25,-110.5 355.25,-110.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"395.5\" y=\"-123.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.1044</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"435.75,-110.75 435.75,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"479\" y=\"-123.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;5.5292</text>\n",
       "</g>\n",
       "<!-- 2233360765744&#45;&gt;2233360773232+ -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>2233360765744&#45;&gt;2233360773232+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M522.15,-128.5C538.72,-128.5 555.35,-128.5 569.41,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"569.08,-132 579.08,-128.5 569.08,-125 569.08,-132\"/>\n",
       "</g>\n",
       "<!-- 2233360765744*&#45;&gt;2233360765744 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2233360765744*&#45;&gt;2233360765744</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M297.42,-128.5C310.58,-128.5 327.36,-128.5 344.71,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"344.55,-132 354.55,-128.5 344.55,-125 344.55,-132\"/>\n",
       "</g>\n",
       "<!-- 2233360764304 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>2233360764304</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"333,-0.5 333,-36.5 544.5,-36.5 544.5,-0.5 333,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-13.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w_2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"373,-0.75 373,-36.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"415.5\" y=\"-13.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;0.9500</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"458,-0.75 458,-36.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"501.25\" y=\"-13.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;5.2567</text>\n",
       "</g>\n",
       "<!-- 2233360764304&#45;&gt;2233360772656* -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>2233360764304&#45;&gt;2233360772656*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M515.74,-36.44C525.5,-39.22 535.29,-42.26 544.5,-45.5 554.84,-49.14 565.82,-53.81 575.63,-58.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"573.81,-61.78 584.35,-62.86 576.78,-55.44 573.81,-61.78\"/>\n",
       "</g>\n",
       "<!-- 2233360771936 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>2233360771936</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-83.5 0,-119.5 207,-119.5 207,-83.5 0,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"20\" y=\"-96.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w_1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"40,-83.75 40,-119.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"80.25\" y=\"-96.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.2789</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"120.5,-83.75 120.5,-119.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.75\" y=\"-96.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;2.0709</text>\n",
       "</g>\n",
       "<!-- 2233360771936&#45;&gt;2233360765744* -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>2233360771936&#45;&gt;2233360765744*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M206.81,-118.29C215.96,-119.79 224.75,-121.24 232.71,-122.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"231.9,-126.12 242.33,-124.29 233.03,-119.21 231.9,-126.12\"/>\n",
       "</g>\n",
       "<!-- 2233360762192 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>2233360762192</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2131,-218.5 2131,-254.5 2293.5,-254.5 2293.5,-218.5 2131,-218.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2171.25\" y=\"-231.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 1.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"2211.5,-218.75 2211.5,-254.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2252.5\" y=\"-231.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 7.6430</text>\n",
       "</g>\n",
       "<!-- 2233360762192&#45;&gt;2233360772800* -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>2233360762192&#45;&gt;2233360772800*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2293.11,-220.78C2302.34,-218.96 2311.37,-217.19 2319.57,-215.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2320.03,-218.85 2329.17,-213.49 2318.68,-211.98 2320.03,-218.85\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x207feacc5e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backward pass\n",
    "loss.backward(); loss.label = 'loss'\n",
    "draw_dot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think through what direction we should be going if we want to decrease the loss. We can see that the gradients for the weights are $\\frac{d_{loss}}{dw_1}=-2.07$, $\\frac{d_{loss}}{dw_2}=-5.26$, and $\\frac{d_{loss}}{db}=-5.53$, while $loss=7.64$. So if we want to decrease the loss, we need to increase the weights. This means moving in the opposite direction of the gradients (which is always the case).\n",
    "\n",
    "The size of the movement is given by `learning_rate`, which is a value that often must be fine-tuned to get the best results. Too small of a learning rate will result in slow training, while too large of a learning rate will result in the model overshooting the optimal weights and never converging.\n",
    "\n",
    "![learning_rate](img/learning_rate.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(neuron, learning_rate=0.01):\n",
    "    for parameter in neuron.parameters():\n",
    "        parameter.data -= parameter.grad * learning_rate\n",
    "    neuron.zero_grad()  # Reset the gradients to zero\n",
    "    return neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(0.2789, grad=-2.0709, label=w_1), Value(-0.9500, grad=-5.2567, label=w_2)] Value(-0.4499, grad=-5.5292, label=b)\n",
      "[Value(0.2996, grad=0.0000, label=w_1), Value(-0.8974, grad=0.0000, label=w_2)] Value(-0.3946, grad=0.0000, label=b)\n"
     ]
    }
   ],
   "source": [
    "# Weights before and after update\n",
    "print(linear_model.w, linear_model.b)\n",
    "linear_model = update_weights(linear_model, learning_rate=0.01)\n",
    "print(linear_model.w, linear_model.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check if the loss has decreased after one iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(7.0308, grad=0.0000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = linear_model(x[0])\n",
    "loss = mse(y[0], output)\n",
    "loss  # Previous loss = 7.6430"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! We've moved the weights in a direction that lowers the loss. \n",
    "\n",
    "The proccess of iteratively moving the weights to reduce the loss is called gradient descent. The whole proccess of training a model with gradient descent can be summarized as follows:\n",
    "\n",
    "1. Predict the output given the input data and current weights.\n",
    "2. Compute the loss between the predicted and actual values.\n",
    "3. Compute the gradient of the loss with respect to the weights.\n",
    "4. Move the weights in the direction opposite to the gradient to reduce the loss.\n",
    "\n",
    "We can now extend this to all samples over multiple iterations to train our linear model properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1.6482\n",
      "1: 0.6424\n",
      "2: 0.3794\n",
      "3: 0.2864\n",
      "4: 0.2365\n",
      "5: 0.2006\n",
      "6: 0.1717\n",
      "7: 0.1476\n",
      "8: 0.1272\n",
      "9: 0.1099\n",
      "10: 0.0952\n",
      "11: 0.0826\n",
      "12: 0.0720\n",
      "13: 0.0628\n",
      "14: 0.0550\n",
      "15: 0.0482\n",
      "16: 0.0425\n",
      "17: 0.0375\n",
      "18: 0.0332\n",
      "19: 0.0295\n",
      "20: 0.0262\n",
      "21: 0.0234\n",
      "22: 0.0210\n",
      "23: 0.0189\n",
      "24: 0.0170\n",
      "25: 0.0154\n",
      "26: 0.0140\n",
      "27: 0.0128\n",
      "28: 0.0117\n",
      "29: 0.0107\n",
      "30: 0.0099\n",
      "31: 0.0091\n",
      "32: 0.0085\n",
      "33: 0.0079\n",
      "34: 0.0074\n",
      "35: 0.0069\n",
      "36: 0.0065\n",
      "37: 0.0062\n",
      "38: 0.0059\n",
      "39: 0.0056\n",
      "40: 0.0054\n",
      "41: 0.0051\n",
      "42: 0.0049\n",
      "43: 0.0048\n",
      "44: 0.0046\n",
      "45: 0.0045\n",
      "46: 0.0044\n",
      "47: 0.0043\n",
      "48: 0.0042\n",
      "49: 0.0041\n",
      "50: 0.0040\n",
      "51: 0.0039\n",
      "52: 0.0039\n",
      "53: 0.0038\n",
      "54: 0.0038\n",
      "55: 0.0037\n",
      "56: 0.0037\n",
      "57: 0.0036\n",
      "58: 0.0036\n",
      "59: 0.0036\n",
      "60: 0.0036\n",
      "61: 0.0035\n",
      "62: 0.0035\n",
      "63: 0.0035\n",
      "64: 0.0035\n",
      "65: 0.0035\n",
      "66: 0.0035\n",
      "67: 0.0034\n",
      "68: 0.0034\n",
      "69: 0.0034\n",
      "70: 0.0034\n",
      "71: 0.0034\n",
      "72: 0.0034\n",
      "73: 0.0034\n",
      "74: 0.0034\n",
      "75: 0.0034\n",
      "76: 0.0034\n",
      "77: 0.0034\n",
      "78: 0.0034\n",
      "79: 0.0034\n",
      "80: 0.0034\n",
      "81: 0.0034\n",
      "82: 0.0034\n",
      "83: 0.0034\n",
      "84: 0.0034\n",
      "85: 0.0034\n",
      "86: 0.0034\n",
      "87: 0.0034\n",
      "88: 0.0034\n",
      "89: 0.0034\n",
      "90: 0.0034\n",
      "91: 0.0034\n",
      "92: 0.0034\n",
      "93: 0.0034\n",
      "94: 0.0034\n",
      "95: 0.0034\n",
      "96: 0.0034\n",
      "97: 0.0033\n",
      "98: 0.0033\n",
      "99: 0.0033\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, num_iterations, learning_rate):\n",
    "    # Trains the model with gradient descent\n",
    "    for i in range(num_iterations):\n",
    "        # Forward Pass\n",
    "        ouputs = (model(xi) for xi in x)\n",
    "        loss = mse(y, ouputs)\n",
    "        # Backward Pass\n",
    "        loss.backward()\n",
    "        # Update\n",
    "        update_weights(model, learning_rate=learning_rate)\n",
    "        print(f'{i}: {loss.data:.4f}')\n",
    "\n",
    "linear_model = Neuron(num_inputs=2, activation='linear')  # reset the weights\n",
    "train_model(linear_model, num_iterations=100, learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(2.0056, grad=0.0000, label=w_1),\n",
       " Value(0.8337, grad=0.0000, label=w_2),\n",
       " Value(0.0766, grad=0.0000, label=b)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear neuron works. It predicts the relationship to be $\\hat{y}=2.0056x_1+0.8337x_2+0.0766+\\epsilon$, which is pretty close to the true relationship $y=2x_1+0.8x_2+\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = [linear_model(xi).data for xi in x]\n",
    "\n",
    "# plot scatter of y vs y_pred\n",
    "plt.scatter(y, y_pred)\n",
    "plt.xlabel('$y$ (true value)')\n",
    "plt.ylabel('$\\hat{y}$ (prediction)')\n",
    "plt.title('Neuron Prediction vs True Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now move on to connecting together multiple (non-linear) neurons to form a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "A neural network is a collection of artificial neurons, grouped into layers. \n",
    "Within each layer, neurons operate independently as they are not interconnected. However, each neuron connects to every other neuron in the layer before and after. You can see an illustration of a neural network below.\n",
    "\n",
    "![A neural network](img/neural_network.jpg)\n",
    "\n",
    "Here's a basic breakdown:\n",
    "\n",
    "- **Input Layer**: The first \"layer\" of the network is the raw input data, and not artificial neurons. The number of items in this layer is the number of input features.\n",
    "- **Hidden Layers**: After the input layer, we have the \"hidden\" layer(s). These layers take the output of the previous layer, processes and transforms it using artificial neurons. We can stack many of these layers where the output of the neurons one layer is the input of the neurons in the next layer. Each neuron in this layer is connected to every neuron in the previous and next layer.\n",
    "- **Output Layer**: This is the final layer, which produces the result. The activation function used in the output layer differs from the hidden layers and depends on the task at hand. For example, in a binary classification task, the output layer might have a [sigmoid activation function](https://en.wikipedia.org/wiki/Logistic_function) which squishes the output between 0 and 1 to represent the probability of belonging to the positive class.\n",
    "- **Weights**: Each connection between neurons has a weight, which determines the strength of the connection. During training, the weights are adjusted to optimize the network's performance using backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the neuron, we'll first implement a hard-coded neural network before generalizing.\n",
    "\n",
    " We'll create the network which was illustrated above. It consists of an input layer with three features, two hidden layers with four neurons each, and an output layer with a single neuron. We'll use the $\\tanh$ activation function for the hidden layers. We will pretend that we do a regression task so we'll use a linear activation function for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [Value(2.0, label='x_1'), Value(0.0, label='x_2'), Value(-3.0, label='x_3')]  # inputs\n",
    "y = [Value(1.0, label='y')]  # outputs\n",
    "\n",
    "hidden_layer1 = [Neuron(3), Neuron(3), Neuron(3), Neuron(3)]  # Uses tanh activation by default\n",
    "hidden_layer2 = [Neuron(4), Neuron(4), Neuron(4), Neuron(4)]\n",
    "output_layer = Neuron(4, activation='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure for training a network is very similar to that of a single neuron. We'll use the same MSE loss function and gradient descent algorithm as before. Remember that the proccess of training a model is as follows: \n",
    "\n",
    "1. Predict the output given the input data and current weights.\n",
    "2. Compute the loss between the predicted and actual values.\n",
    "3. Compute the gradient of the loss with respect to the weights.\n",
    "4. Move the weights in the direction opposite to the gradient to reduce the loss.\n",
    "\n",
    "We start with the forward pass of the network. It is done by passing the outputs of one layer to the next, until we reach the last layer which gives us the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(-1.3343, grad=0.0000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass\n",
    "\n",
    "# First hidden layer\n",
    "a_1 = [neuron(x) for neuron in hidden_layer1]\n",
    "# Second hidden layer\n",
    "a_2 = [neuron(a_1) for neuron in hidden_layer2]  # The input is the output of the first hidden layer\n",
    "# Output layer\n",
    "yhat = output_layer(a_2)  # The input is the output of the second hidden layer\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(5.4491, grad=0.0000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(y, yhat)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the single neuron, the backward pass is as simple ass calling `.backward()` on the loss value to compute the gradients of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to update our weights using the gradients from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the parameters\n",
    "def update_weights(model, learning_rate=0.01):  # Redefined here for your convenience\n",
    "    for parameter in model.parameters():\n",
    "        parameter.data -= parameter.grad * learning_rate\n",
    "    model.zero_grad()  # Reset the gradients to zero\n",
    "\n",
    "LR = 0.01\n",
    "\n",
    "update_weights(output_layer, LR)\n",
    "for neuron in hidden_layer2:\n",
    "    update_weights(neuron, LR)\n",
    "for neuron in hidden_layer1:\n",
    "    update_weights(neuron, LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check that the proccess works by redoing the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(4.1383, grad=0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "a_1 = [neuron(x) for neuron in hidden_layer1]\n",
    "a_2 = [neuron(a_1) for neuron in hidden_layer2]\n",
    "yhat = output_layer(a_2)\n",
    "loss = mse(y, yhat)\n",
    "print(loss)  # Previous loss = 5.4491"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success again! We'll now generalize what we just did by creating two new classes `Layer` and `VanillaNN`. We'll start with `Layer`.\n",
    "\n",
    "The `Layer` class is simple. It is just a list of neurons, the number of which is defined by `num_ouputs`, each taking\n",
    "`num_inputs` of features as inputs. The rest of the interface is the same as in `Neuron`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer([ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)])\n"
     ]
    }
   ],
   "source": [
    "class Layer:\n",
    "    def __init__(self, num_inputs, num_outputs, activation='tanh'):\n",
    "        self.neurons = [Neuron(num_inputs, activation) for _ in range(num_outputs)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"The forward pass of a single layer\"\"\"\n",
    "        out = [n(x) for n in self.neurons]\n",
    "        return out[0] if len(out) == 1 else out\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Return the weights and bias of the whole layer as a list\"\"\"\n",
    "        return [p for n in self.neurons for p in n.parameters()]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Layer({self.neurons})\"\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Reset the gradients to zero\"\"\"\n",
    "        for p in self.parameters():\n",
    "            p.grad = 0\n",
    "\n",
    "layer = Layer(3, 4, activation='relu')\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`VanillaNN` is also just as simple. It is just a list of `Layer`'s. The simplicity of `Layer` and `VanillaNN` testifies to how much of the real work is already implemented by `Value` and `Neuron`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaNN([\n",
       "  Layer([TanhNeuron(3), TanhNeuron(3), TanhNeuron(3), TanhNeuron(3)]),\n",
       "  Layer([TanhNeuron(4), TanhNeuron(4), TanhNeuron(4), TanhNeuron(4)]),\n",
       "  Layer([LinearNeuron(4)])\n",
       "])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VanillaNN:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"The forward pass of a full network\"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Return the weights and bias of the whole network as a list\"\"\"\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "    def __repr__(self):\n",
    "        layers_str = ',\\n  '.join([str(layer) for layer in self.layers])\n",
    "        return f\"VanillaNN([\\n  {layers_str}\\n])\"\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"Reset the gradients to zero\"\"\"\n",
    "        for p in self.parameters():\n",
    "            p.grad = 0\n",
    "\n",
    "layers = [\n",
    "    Layer(3, 4, activation='tanh'),\n",
    "    Layer(4, 4, activation='tanh'),\n",
    "    Layer(4, 1, activation='linear')\n",
    "]\n",
    "nn = VanillaNN(layers)\n",
    "nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a sanity check of our network by implementing a training loop on the same data used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Value: 1.0\n",
      "Prediction before training: 0.5425\n",
      "\n",
      "loss.data=0.2093\n",
      "loss.data=0.0335\n",
      "loss.data=0.0051\n",
      "loss.data=0.0008\n",
      "loss.data=0.0001\n",
      "\n",
      "Prediction after training: 0.9959\n"
     ]
    }
   ],
   "source": [
    "print(f'Actual Value: {y[0].data}')\n",
    "print(f'Prediction before training: {nn(x).data:.4f}\\n')\n",
    "for _ in range(5):\n",
    "    yhat = nn(x)\n",
    "    loss = mse(y, yhat)\n",
    "    print(f'{loss.data=:0.4f}')\n",
    "    loss.backward()\n",
    "    update_weights(nn, learning_rate=0.05)\n",
    "    \n",
    "print(f'\\nPrediction after training: {nn(x).data:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, training on a fake \"dataset\" consisting of one single datapoint isn't exactly interesting, realistic, nor really in the spirit of deep learning. So let's try to train our network on something more akin to a real dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on a real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
